### Oct 30 - Nov 11:  Can Government Play Moneyball?

A [recent editorial](https://www.theatlantic.com/magazine/archive/2013/07/can-government-play-moneyball/309389/) on using Moneyball strategies for government argues that, "less than $1 out of every $100 of government spending is backed by even the most basic evidence that the money is being spent wisely."

> "With so little performance data, it’s impossible to say how many of the programs were effective... Since 1990, the federal government has put 11 large social programs, collectively costing taxpayers more than $10 billion a year, through randomized controlled trials, the gold standard of evaluation. Ten out of the 11—including Upward Bound and Job Corps—showed “weak or no positive effects” on their participants. This is not to say that all 10 programs deserve to be eliminated. But at a minimum, collecting rigorous evidence could help spur programs to improve over time."

The challenge with this line of reasoning is that outcomes in business and baseball are easy to define. Businesses care about profits and returns on investment, and baseball teams care about wins and championships (or profits and return on investment if you are the team owner). 

The trick that Moneyball demonstrated is discovering a [key variable that predicts performance](https://towardsdatascience.com/linear-regression-moneyball-part-2-175a9dc72e89), then figuring out how to buy more for as cheap as possible. 

What about the public sector? The authors argue that, "According to the Institute of Medicine, more than half of treatments provided to patients lack clear evidence that they’re effective. If we could stop ineffective treatments, and swap out expensive treatments for ones that are less expensive but just as effective, we would achieve better outcomes for patients and save money."

How do we measure outcomes, though? Take a couple of simple examples, schools and hospitals. What metrics are commonly used to "moneyball" these industries? Are test scores a good measure of school performance? What about hospitals? If you were going to assign a grade to a hospital, what outcome would you measure? 

When attempts are made to implement "pay for performance" contracts that only pay for results, it can create a powerful peverse incentive. If you are a high school that only gets paid for students that graduate, you face two stark choices. Either you stop admitting students that are unlikely to graduate (if you have that option), or you can lower standards and fudge numbers. Now you look good on paper, right? But the quality of services has not improved, money was not saved, and we potentially have a vulnerable population that no one will serve because they don't want to rack up points in the failure column. 

For a great example of using outcome scores poorly, see the use of "value-added" analysis in the NY public schools (2:20-4:00) presented by the author of *Weapons of Math Destruction*:

<iframe width="560" height="315" src="https://www.youtube.com/embed/_2u_eHHzRto?controls=0&amp;start=142" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

This is not to say that we should not Moneyball Government, but algorithms that allocate resources or benefits based upon performance will benefit some groups, and punish others. We need to recognize that using data to evaluate performance is an inherently political act that requires transparency and humility. What are some positive and some negative examples of how data has been used to improve government, or to corrupt and distort it? 
